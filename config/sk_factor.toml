[dataset]
loader = 'csv'
# Debug unprocessed columns from the dataset
show_columns = true
# Ignored if -t (--train_files) is passed to the CLI.
# files = []
# You can choose override plugins from a custom package,
# it has to follow sk_factor's plugin directory structure.
# plugins = 'examples.iris'

[preprocess]
label = 'target'
label_encode = true
# The shuffle value is its random_state seed.
preprocessors.shuffle = 1
preprocessors.drop_rows = -3
# Dropped samples left out for predictions (relevant for testing the final model):
drop_rows_to_predict_file = true
# Gather merged files IDs in a reserved column named 'group':
groupFiles = false
# preprocessors.drop_columns = ['column_unwanted']
# preprocessors.drop_na = []
#  Pass features as is to the pipeline, empty list to keep all features.
transformers.passthrough = []

#  Use with groups = true above, will encode groups from train filenames:
# transformers.ordinal_encoder = ['group']

#  Encode groups in their own column (beware you cannot split on one hot encoder groups):
# transformers.one_hot_encoder = ['group']

# Pipeline suffixes are removed from columns by default:
verbose_feature_names_out = false

# Multiple files will be combined, by default the "index" axis is used.
# If 'index' axis is used, a group column with the filename will be added.
# If 'column' axis is used, no grouping will occur.
files_axis = 'index'

[eda]
enabled = false
# show_plots and save_images are used for training plots also,
# regardless of eda enabled.
show_plots = false
save_images = false
save_timestamp = true
images_extension = 'png'
images_directory = 'output/eda'
plots = [
  'heatmap',
  'pairplot',
  'distribution_x',
  'distribution_y',
]
# distribution_x=column_a
figsize = [35, 35]
dpi = 200
# features = ['column a', 'column b', 'column n']

[training]
# Disable to do eda only.
enabled = true
pipeline = 'imblearn.pipeline'
# Optionnals steps (@see plugins/estimators/):
# samplers = [
#     'sampler/near_miss',
# ]
# transformers = [
#     'transformer/yeo_johnson',
# ]
estimators = [
    'regressor/lgbm_classifier',
  ]
runners = [
    'score'
    # 'confusion_matrix',
    # precision_recall
  ]
# Split method is a dict with the number of split as value.
splitting_method.kfold_shuffle = 3
splitting_method.kfold_stratified = 4
# Some splitting option only affect related splitter:
splitting_random_state = nan
splitting_test_size = 0.2
splitting_n_repeats = 10
splitting_group = 'group'
# @see https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values
scoring = 'accuracy'
# A model will be trained from the whole dataset and saved.
save_model = false
# Model will be named by config name, .pkl extension.
models_directory = 'models'
# Append timestamp to model filename.
model_timestamp = false
# Use a random seed (default) or specify one
seed = 'random'

[predictions]
enabled = false
loader = 'csv'
predict_file = 'path/to/test.csv'
# Leave out the models param to use fitted pipelines from the previous training.
# models = [
#   'models/iris.pkl'
# ]
# Available plugins: binary, multiclass, regressor
objective = 'multiclass'
# Use the preprocess, as in training. Set to false if preprocessors.drop_rows is used.
preprocess = false
threshold = 0.5
predictions_directory = 'output/predictions'
save_predictions = false
predictions_timestamp = true
# Keep X data features in the final predictions columns.
keep_data = false

[debug]
port = 5678
host = '127.0.0.1'
wait_for_client = true
# Ignored if -d (--debug) is passed to the CLI
enabled = false
