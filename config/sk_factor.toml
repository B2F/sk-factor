[dataset]
loader = 'csv'
# Debug unprocessed columns from the dataset
show_columns = false
# Ignored if -t (--train_files) is passed to the CLI.
# files = []
# You can choose a custom plugin package, it has to follow sk_factor's plugin directory structure.
# plugins = 'examples.iris'

[preprocess]
label = 'target'
label_encode = true
# Gather merged files IDs in a reserved column named 'group':
groupFiles = false
# preprocessors.drop_columns = ['column_unwanted']
# preprocessors.drop_na = []
#  Pass features as is to the pipeline, empty list to keep all features.
transformers.passthrough = []

#  Use with groups = true above, will encode groups from train filenames:
# transformers.ordinal_encoder = ['group']

#  Encode groups in their own column (beware you cannot split on one hot encoder groups):
# transformers.one_hot_encoder = ['group']

# Pipeline suffixes are removed from columns by default:
verbose_feature_names_out = false

# @todo: implement pipeline save method.
save_transformers_pipeline = false
transformers_pipeline_directory = 'output/transformers'
# Multiple files will be combined, by default the "index" axis is used.
# If 'index' axis is used, a group column with the filename will be added.
# If 'column' axis is used, no grouping will occur.
files_axis = 'index'

[eda]
show_plots = false
save_images = false
save_timestamp = true
images_extension = 'png'
images_directory = 'output/eda'
plots = [
  'heatmap',
  'pairplot',
  'distribution_x',
  'distribution_y',
]
# distribution_x=column_a
figsize = [35, 35]
dpi = 200
# features = ['column a', 'column b', 'column n']

[training]
# Disable to do eda only.
enabled = true
pipeline = 'imblearn.pipeline'
estimators = [
    # 'power_transforms/yeo_johnson',
    # 'sampler/tomek_links',
    'classifier/lgbm_random_forest_mc',
    # 'regressor/lgbm_rf_regressor',
  ]
runners = [
    'score'
    # 'confusion_matrix',
    # precision_recall
  ]
# Split method is a dict with the number of split as value.
splitting_methods.kfold_shuffle = 3
splitting_methods.kfold_stratified = 4
# Some splitting option only affect related splitter:
splitting_random_state = nan
splitting_test_size = 0.2
splitting_n_repeats = 10
splitting_group = 'group'
# @see https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values
scoring = 'accuracy'
# A model will be trained from the whole dataset and saved.
save_model = false
model_timestamp = false
models_directory = 'models'
# Use a random seed (default) or specify one
seed = 'random'

[predictions]
# @todo predictions:
# Will use training by default, else use a model_file if specified.
# model_file = model
predictions_directory = 'output/predictions'
save_predictions = false
predictions_timestamp = true
# @todo: apply the threshold to class output
roundpredictions = false
# @see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter

[debug]
port = 5678
host = '127.0.0.1'
wait_for_client = true
# Ignored if -d (--debug) is passed to the CLI
enabled = false
